{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up Google Colab environment\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Step 2: Download and extract the Flowers 102 dataset\n",
        "# URL to the dataset\n",
        "url = \"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\n",
        "annotations_url = \"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\"\n",
        "split_url = \"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat\"\n",
        "\n",
        "# Directories for the dataset and annotations\n",
        "data_dir = \"./flowers102\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# Download the dataset\n",
        "urllib.request.urlretrieve(url, os.path.join(data_dir, \"102flowers.tgz\"))\n",
        "urllib.request.urlretrieve(annotations_url, os.path.join(data_dir, \"imagelabels.mat\"))\n",
        "urllib.request.urlretrieve(split_url, os.path.join(data_dir, \"setid.mat\"))\n",
        "\n",
        "# Extract the dataset\n",
        "with tarfile.open(os.path.join(data_dir, \"102flowers.tgz\"), \"r:gz\") as tar:\n",
        "    tar.extractall(path=data_dir)\n",
        "\n",
        "# Step 3: Organize the dataset into train, validation, and test directories\n",
        "import scipy.io\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the labels and splits\n",
        "labels = scipy.io.loadmat(os.path.join(data_dir, \"imagelabels.mat\"))[\"labels\"][0]\n",
        "setid = scipy.io.loadmat(os.path.join(data_dir, \"setid.mat\"))\n",
        "train_ids = setid[\"trnid\"][0]\n",
        "val_ids = setid[\"valid\"][0]\n",
        "test_ids = setid[\"tstid\"][0]\n",
        "\n",
        "# Helper function to create directories\n",
        "def create_dataset_split(ids, split_name):\n",
        "    split_dir = os.path.join(data_dir, split_name)\n",
        "    if not os.path.exists(split_dir):\n",
        "        os.makedirs(split_dir)\n",
        "\n",
        "    for idx in ids:\n",
        "        label = labels[idx - 1]\n",
        "        src_path = os.path.join(data_dir, \"jpg\", f\"image_{idx:05d}.jpg\")\n",
        "        dest_dir = os.path.join(split_dir, str(label))\n",
        "        if not os.path.exists(dest_dir):\n",
        "            os.makedirs(dest_dir)\n",
        "        shutil.move(src_path, os.path.join(dest_dir, f\"image_{idx:05d}.jpg\"))\n",
        "\n",
        "# Create train, validation, and test splits\n",
        "create_dataset_split(train_ids, \"train\")\n",
        "create_dataset_split(val_ids, \"val\")\n",
        "create_dataset_split(test_ids, \"test\")\n",
        "\n",
        "# Step 4: Create DataLoaders using torchvision.datasets.ImageFolder\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transforms\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Create datasets\n",
        "image_datasets = {\n",
        "    \"train\": datasets.ImageFolder(os.path.join(data_dir, \"train\"), data_transforms[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(os.path.join(data_dir, \"val\"), data_transforms[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(os.path.join(data_dir, \"test\"), data_transforms[\"test\"])\n",
        "}\n",
        "\n",
        "# Create dataloaders\n",
        "dataloaders = {\n",
        "    \"train\": DataLoader(image_datasets[\"train\"], batch_size=batch_size, shuffle=True, num_workers=2),\n",
        "    \"val\": DataLoader(image_datasets[\"val\"], batch_size=batch_size, shuffle=False, num_workers=2),\n",
        "    \"test\": DataLoader(image_datasets[\"test\"], batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "}\n",
        "\n",
        "# Example of iterating through the DataLoader\n",
        "# for inputs, labels in dataloaders['train']:\n",
        "#     print(inputs.shape, labels.shape)\n",
        "#     break"
      ],
      "metadata": {
        "id": "zh6pd1bXokXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Specify dataset directory\n",
        "data_dir = 'path/to/your/dataset'\n",
        "\n",
        "# Define data transformations\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load dataset\n",
        "full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\"\"\"\n",
        "train_dataset = image_datasets['train']\n",
        "val_dataset = image_datasets['val']\n",
        "test_dataset = image_datasets['test']\n",
        "train_loader = dataloaders['train']\n",
        "val_loader = dataloaders['val']\n",
        "test_loader = dataloaders['test']"
      ],
      "metadata": {
        "id": "zwrDgTcTfrWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Define the Bilinear CNN model\n",
        "class BilinearCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BilinearCNN, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Identity()  # Remove the fully connected layer\n",
        "\n",
        "        self.fc = nn.Linear(2048 * 2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)  # [batch_size, 2048, 7, 7]\n",
        "        features = features.view(features.size(0), 2048, -1)  # [batch_size, 2048, 49]\n",
        "        bilinear_features = torch.bmm(features, features.transpose(1, 2))  # [batch_size, 2048, 2048]\n",
        "        bilinear_features = bilinear_features.view(features.size(0), -1)  # [batch_size, 2048 * 2048]\n",
        "\n",
        "        bilinear_features = torch.sqrt(bilinear_features + 1e-5)\n",
        "        bilinear_features = nn.functional.normalize(bilinear_features)\n",
        "\n",
        "        output = self.fc(bilinear_features)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(train_dataset.classes)  # Adjust to match the number of classes in your dataset\n",
        "model = BilinearCNN(num_classes=num_classes).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DXYzkxHJ43V",
        "outputId": "b82c0f63-c3cf-4905-fe2c-515109497e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 158MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Define training parameters\n",
        "num_epochs = 16\n"
      ],
      "metadata": {
        "id": "E0XSBF_iLS3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()  # Set model to training mode\n",
        "            dataloader = train_loader\n",
        "        else:\n",
        "            model.eval()  # Set model to evaluate mode\n",
        "            dataloader = val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # Backward pass and optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Deep copy the model\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzPtXnxYLUop",
        "outputId": "c572fc6a-e919-4a74-e10f-d2b3a62a6adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/15\n",
            "----------\n",
            "train Loss: 4.6251 Acc: 0.0039\n",
            "val Loss: 4.6248 Acc: 0.0225\n",
            "Epoch 1/15\n",
            "----------\n",
            "train Loss: 4.6249 Acc: 0.0108\n",
            "val Loss: 4.6247 Acc: 0.0382\n",
            "Epoch 2/15\n",
            "----------\n",
            "train Loss: 4.6247 Acc: 0.0137\n",
            "val Loss: 4.6245 Acc: 0.0745\n",
            "Epoch 3/15\n",
            "----------\n",
            "train Loss: 4.6245 Acc: 0.0637\n",
            "val Loss: 4.6243 Acc: 0.1176\n",
            "Epoch 4/15\n",
            "----------\n",
            "train Loss: 4.6243 Acc: 0.1029\n",
            "val Loss: 4.6241 Acc: 0.2176\n",
            "Epoch 5/15\n",
            "----------\n",
            "train Loss: 4.6241 Acc: 0.1725\n",
            "val Loss: 4.6239 Acc: 0.2480\n",
            "Epoch 6/15\n",
            "----------\n",
            "train Loss: 4.6240 Acc: 0.1441\n",
            "val Loss: 4.6237 Acc: 0.2422\n",
            "Epoch 7/15\n",
            "----------\n",
            "train Loss: 4.6238 Acc: 0.2157\n",
            "val Loss: 4.6235 Acc: 0.3657\n",
            "Epoch 8/15\n",
            "----------\n",
            "train Loss: 4.6236 Acc: 0.2176\n",
            "val Loss: 4.6233 Acc: 0.3608\n",
            "Epoch 9/15\n",
            "----------\n",
            "train Loss: 4.6234 Acc: 0.3029\n",
            "val Loss: 4.6231 Acc: 0.4265\n",
            "Epoch 10/15\n",
            "----------\n",
            "train Loss: 4.6232 Acc: 0.3824\n",
            "val Loss: 4.6229 Acc: 0.5078\n",
            "Epoch 11/15\n",
            "----------\n",
            "train Loss: 4.6230 Acc: 0.4265\n",
            "val Loss: 4.6227 Acc: 0.5000\n",
            "Epoch 12/15\n",
            "----------\n",
            "train Loss: 4.6228 Acc: 0.4137\n",
            "val Loss: 4.6225 Acc: 0.4990\n",
            "Epoch 13/15\n",
            "----------\n",
            "train Loss: 4.6226 Acc: 0.4863\n",
            "val Loss: 4.6223 Acc: 0.5559\n",
            "Epoch 14/15\n",
            "----------\n",
            "train Loss: 4.6224 Acc: 0.4686\n",
            "val Loss: 4.6221 Acc: 0.5078\n",
            "Epoch 15/15\n",
            "----------\n",
            "train Loss: 4.6222 Acc: 0.4725\n",
            "val Loss: 4.6219 Acc: 0.5667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "model.eval()\n",
        "running_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "print(f'Test Acc: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QiOsB7MLd1b",
        "outputId": "281ff79f-38bd-4120-ba01-616c5f911c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.5633\n"
          ]
        }
      ]
    }
  ]
}